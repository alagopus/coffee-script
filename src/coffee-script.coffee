# CoffeeScript can be used both on the server, as a command-line compiler based
# on Node.js/V8, or to run CoffeeScripts directly in the browser. This module
# contains the main entry functions for tokenizing, parsing, and compiling
# source CoffeeScript into JavaScript.
#
# If included on a webpage, it will automatically sniff out, compile, and
# execute all scripts present in `text/coffeescript` tags.

file      = require 'file'
{Lexer}   = require './lexer'
{parser}  = require './parser'

# The file extensions that are considered to be CoffeeScript.
extensions = ['.coffee', '.litcoffee']

compileJS = (scope, code, filename) ->
  code = String(code)
  scope = global unless scope?
  Packages.org.mozilla.javascript.Context.getCurrentContext().evaluateString scope, code, filename, 0, null

# Load and run a CoffeeScript file for Node, stripping any `BOM`s.
loadFile = (module, filename) ->
  raw = file.read filename, { charset: 'utf-8' }
  stripped = if raw.charCodeAt(0) is 0xFEFF then raw.substring 1 else raw
  compileJS module, compile(stripped, {filename}), filename

if require.extensions
  for ext in extensions
    require.extensions[ext] = loadFile

# The current CoffeeScript version number.
exports.VERSION = '1.5.0-pre'

# Expose helpers for testing.
exports.helpers = require './helpers'

# Compile a string of CoffeeScript code to JavaScript, using the Coffee/Jison
# compiler.
exports.compile = compile = (code, options = {}) ->
  {merge} = exports.helpers
  try
    js = (parser.parse lexer.tokenize(code, options)).compile options
    return js unless options.header
  catch err
    err.message = "In #{options.filename}, #{err.message}" if options.filename
    throw err
  header = "Generated by CoffeeScript #{@VERSION}"
  "// #{header}\n#{js}"

# Tokenize a string of CoffeeScript code, and return the array of tokens.
exports.tokens = (code, options) ->
  lexer.tokenize code, options

# Parse a string of CoffeeScript code or an array of lexed tokens, and
# return the AST. You can then compile it by calling `.compile()` on the root,
# or traverse it by using `.traverseChildren()` with a callback.
exports.nodes = (source, options) ->
  if typeof source is 'string'
    parser.parse lexer.tokenize source, options
  else
    parser.parse source

# Compile and execute a string of CoffeeScript (on the server), correctly
# setting `__filename`, `__dirname`, and relative `require()`.
exports.run = (code, options = {}) ->
  mainModule = require.main

  # Set the filename.
  mainModule.filename = global.arguments[0] =
      if options.filename then file.canonical(options.filename) else '.'

  # Clear the module cache.
  mainModule.moduleCache and= {}

  # Assign paths for node_modules loading
  mainModule.paths = [ file.dirname file.canonical options.filename ]

  # Compile.
  code = compile(code, options) unless (file.extension(mainModule.filename) not in extensions) or require.extensions
  compileJS mainModule, code, mainModule.filename

# Compile and evaluate a string of CoffeeScript.
# The CoffeeScript REPL uses this to run the input.
exports.eval = (code, options = {}) ->
  return unless code = code.trim()
  if options.sandbox?
    sandbox = options.sandbox
    sandbox.global = sandbox.root = sandbox.GLOBAL = sandbox
  else
    sandbox = global
  sandbox.__filename = options.filename || 'eval'
  sandbox.__dirname  = file.dirname sandbox.__filename
  o = {}
  o[k] = v for own k, v of options
  o.bare = on # ensure return value
  js = compile code, o
  compileJS sandbox, js, sandbox.__filename

# Instantiate a Lexer for our use here.
lexer = new Lexer

# The real Lexer produces a generic stream of tokens. This object provides a
# thin wrapper around it, compatible with the Jison API. We can then pass it
# directly as a "Jison lexer".
parser.lexer =
  lex: ->
    [tag, @yytext, @yylineno] = @tokens[@pos++] or ['']
    tag
  setInput: (@tokens) ->
    @pos = 0
  upcomingInput: ->
    ""

parser.yy = require './nodes'
